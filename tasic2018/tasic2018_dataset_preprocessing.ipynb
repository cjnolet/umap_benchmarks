{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **tasic2018** dataset preprocessing\n",
    "\n",
    "Thanks to **Dmitry Kobak** for his excellent repository on the art of using t-SNE for single-cell transcriptomics : https://github.com/berenslab/rna-seq-tsne\n",
    "\n",
    "Original notebook making use of **tasic2018** : https://github.com/berenslab/rna-seq-tsne/blob/master/demo.ipynb\n",
    "\n",
    "Feel free to take a look at the original notebook to get a better comprehension of the creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the **Allen institute** for providing the **tasic2018** dataset.\n",
    "\n",
    "Website : http://celltypes.brain-map.org/rnaseq\n",
    "\n",
    "In order to preprocess the dataset, download the necessary data :\n",
    "- Download and extract the following archives in tasic2018 directory :\n",
    "    - VISp: http://celltypes.brain-map.org/api/v2/well_known_file_download/694413985\n",
    "    - ALM: http://celltypes.brain-map.org/api/v2/well_known_file_download/694413179\n",
    "- Open the interactive data browser http://celltypes.brain-map.org/rnaseq/mouse/v1-alm, go to \"Sample Heatmaps\", click \"Build Plot!\" and then \"Download data as CSV\" and download the CSV file in the tasic2018 directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................. done\n"
     ]
    }
   ],
   "source": [
    "# Load the Allen institute data. This takes a few minutes\n",
    "\n",
    "# This function is needed because using Pandas to load these files in one go \n",
    "# can eat up a lot of RAM. So we are doing it in chunks, and converting each\n",
    "# chunk to the sparse matrix format on the fly.\n",
    "def sparseload(filenames):\n",
    "    genes = []\n",
    "    sparseblocks = []\n",
    "    areas = []\n",
    "    cells = []\n",
    "    for chunk1,chunk2 in zip(pd.read_csv(filenames[0], chunksize=1000, index_col=0, na_filter=False),\n",
    "                             pd.read_csv(filenames[1], chunksize=1000, index_col=0, na_filter=False)):\n",
    "        if len(cells)==0:\n",
    "            cells = np.concatenate((chunk1.columns, chunk2.columns))\n",
    "            areas = [0]*chunk1.columns.size + [1]*chunk2.columns.size\n",
    "        \n",
    "        genes.extend(list(chunk1.index))\n",
    "        sparseblock1 = sparse.csr_matrix(chunk1.values.astype(float))\n",
    "        sparseblock2 = sparse.csr_matrix(chunk2.values.astype(float))\n",
    "        sparseblock = sparse.hstack((sparseblock1,sparseblock2), format='csr')\n",
    "        sparseblocks.append([sparseblock])\n",
    "        print('.', end='', flush=True)\n",
    "    print(' done')\n",
    "    counts = sparse.bmat(sparseblocks)\n",
    "    return (counts.T, np.array(genes), cells, np.array(areas))\n",
    "\n",
    "filenames = ['mouse_VISp_2018-06-14_exon-matrix.csv',\n",
    "             'mouse_ALM_2018-06-14_exon-matrix.csv']\n",
    "counts, genes, cells, areas = sparseload(filenames)\n",
    "\n",
    "genesDF = pd.read_csv('mouse_VISp_2018-06-14_genes-rows.csv')\n",
    "ids     = genesDF['gene_entrez_id'].tolist()\n",
    "symbols = genesDF['gene_symbol'].tolist()\n",
    "id2symbol = dict(zip(ids, symbols))\n",
    "genes = np.array([id2symbol[g] for g in genes])\n",
    "\n",
    "clusterInfo = pd.read_csv('sample_heatmap_plot_data.csv')\n",
    "goodCells  = clusterInfo['sample_name'].values\n",
    "ids        = clusterInfo['cluster_id'].values\n",
    "labels     = clusterInfo['cluster_label'].values\n",
    "colors     = clusterInfo['cluster_color'].values\n",
    "\n",
    "clusterNames  = np.array([labels[ids==i+1][0] for i in range(np.max(ids))])\n",
    "clusterColors = np.array([colors[ids==i+1][0] for i in range(np.max(ids))])\n",
    "clusters   = np.copy(ids) - 1\n",
    "\n",
    "ind = np.array([np.where(cells==c)[0][0] for c in goodCells])\n",
    "counts = counts[ind, :]\n",
    "\n",
    "tasic2018 = {'counts': counts, 'genes': genes, 'clusters': clusters, 'areas': areas, \n",
    "             'clusterColors': clusterColors, 'clusterNames': clusterNames}\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "\n",
    "def nearZeroRate(data, threshold=0):\n",
    "    zeroRate = 1 - np.squeeze(np.array((data>threshold).mean(axis=0)))\n",
    "    return zeroRate\n",
    "\n",
    "def meanLogExpression(data, threshold=0, atleast=10):\n",
    "    nonZeros = np.squeeze(np.array((data>threshold).sum(axis=0)))\n",
    "    N = data.shape[0]\n",
    "    A = data.multiply(data>threshold)\n",
    "    A.data = np.log2(A.data)\n",
    "    meanExpr = np.zeros(data.shape[1]) * np.nan\n",
    "    detected = nonZeros >= atleast\n",
    "    meanExpr[detected] = np.squeeze(np.array(A[:,detected].mean(axis=0))) / (nonZeros[detected]/N)\n",
    "    return meanExpr\n",
    "    \n",
    "def featureSelection(meanLogExpression, nearZeroRate, yoffset=.02, decay=1.5, n=3000):\n",
    "    low = 0; up=10    \n",
    "    nonan = ~np.isnan(meanLogExpression)\n",
    "    xoffset = 5\n",
    "    for step in range(100):\n",
    "        selected = np.zeros_like(nearZeroRate).astype(bool)\n",
    "        selected[nonan] = nearZeroRate[nonan] > np.exp(-decay*meanLogExpression[nonan] + xoffset) + yoffset\n",
    "        if np.sum(selected) == n:\n",
    "            break\n",
    "        elif np.sum(selected) < n:\n",
    "            up = xoffset\n",
    "            xoffset = (xoffset + low)/2\n",
    "        else:\n",
    "            low = xoffset\n",
    "            xoffset = (xoffset + up)/2\n",
    "    return selected\n",
    "\n",
    "x = meanLogExpression(tasic2018['counts'], threshold=32)  # Get mean log non-zero expression of each gene\n",
    "y = nearZeroRate(tasic2018['counts'], threshold=32)       # Get near-zero frequency of each gene\n",
    "selectedGenes = featureSelection(x, y, n=3000)            # Adjust the threshold to select 3000 genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts3k = tasic2018['counts'][:, selectedGenes]  # Feature selection\n",
    "\n",
    "librarySizes = tasic2018['counts'].sum(axis=1)    # Compute library sizes\n",
    "CPM = counts3k / librarySizes * 1e+6              # Library size normalisation\n",
    "\n",
    "logCPM = np.log2(CPM + 1)                         # Log-transformation\n",
    "\n",
    "pca = PCA(n_components=50, svd_solver='full').fit(logCPM)   # PCA\n",
    "\n",
    "flipSigns = np.sum(pca.components_, axis=1) < 0             # fix PC signs\n",
    "X = pca.transform(logCPM)\n",
    "X[:, flipSigns] *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(X, open(\"tasic2018_X.p\", \"wb\"))\n",
    "pickle.dump(tasic2018['clusterColors'][tasic2018['clusters']], open(\"tasic2018_y.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
